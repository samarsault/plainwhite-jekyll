# Разработка pypi пакета с поддержкой разных версий python

Кто хотел создать полезный open-source пакет для python, который каждый желающий сможет установить заветной командой:
```
pip install my-perfect-package
```
Это небольшой мануал/история о том, как это сделать с подробностями за ссылками.
Расчитана на новичков, но призываю и профессионалов высказать свое мнение, как можно улучшить "идеальный" пакет.

## Как сделать лучший пакет?
Буду исходить из следующих требований:

* **Open source на github;**  
   Каждый должен иметь возможность внести свой вклад в развитие и поблагодарить автора.

* **Поддержка всех актуальных\популярных версий питона (2.7, 3.5, 3.6, 3.7, 3.8);**  
   Питоны бывают разные, и где-то до сих пор активно пишут на 2.7, нужно быть полезным всем.

* **100% покрытие юнит тестами;**    
   ~~Юнит тесты улучшает архитектуру, позволяет автоматизировать регрессионные проверки.~~  
   Бейдж с заветным числом повышает ЧСВ и [задает планку другим](https://cmustrudel.github.io/papers/icse18badges.pdf).

* **Использование CI**  
   Автоматические проверки - это очень удобно! ~~а еще куча клевых бейджей~~

  * **Запуск юнит тестов на всех платформах и на всех версиях питона;**  
     Не стоит верить тем, кто утверждает, что питон и устанавливаемые пакеты - [кроссплатформенные](https://docs.python.org/2/library/os.html), ведь всегда можно натолкнуться на [баг](https://bugs.python.org/issue22587).

  * **Проверка код стайла;**  
     Единый стиль улучшает читаемость и уменьшает количество пустых дискуссий в ревью.

  * **Статический анализатора кода;**  
     Автоматический поиск багов в коде? Дайте два!

* **Актуальная документация**
    Примеры работы с пакетом, описание методов\классов и разбор типичных ошибок - задокументированный опыт позволят упростить работу для новичков.

* **Пакет полезен и делает мир лучше.**  
   Самое сложно требование, так как судя по количеству пакетов в [pypi](https://pypi.org/) *(~210к)* разработчики - дикие альтруисты и многое уже написано.

* **Кроссплатформенность разработки**
   К сожалению, в некоторые проекты сложно вносить свой вклад просто потому, что разработчик заточил инструменты под Linux. К примеру, написал bash скрипты для сборки.

## С чего начать?
Хороших идей не было, поэтому тему выбрал избитую и очень популярную - работа со системами счисления. 

Первая версия должна уметь переводить числа в римские и обратно. Для мануала сложнее и не нужно.

Ах, да, самое важное - это название: ~~numsys - как расшифровка numeral systems.~~ *numeral-system-py*.

## Тесты
Взял *python3.7* и первым делом написал тесты с заглушками функций (мы ведь за [TDD](https://en.wikipedia.org/wiki/Test-driven_development)) с использованием стандартного модуля [unittests](https://habr.com/ru/post/121162/). Для запуска решил использовать [pytest](https://habr.com/ru/post/269759/). Выглядит, возможно, немного не логично, но стадартный модуль мне кажется чуть удобнее (ИМХО) и pytest умеет с ним отлично работать.
Делаю следующую структуру проекта:
```
src/
    numeral-system/
        __init__.py
        roman.py
    tests
        __init__.py
        test_roman.py
```
Тесты в пакет класть не буду, поэтому отделяем ~зёрна от плевел~. Изначально папку src/ не создавал, но дальнейшее развитие показало, что так проще оперировать и настраивать сервисы. 

Сразу встал вопрос, как запускать-то? 
Чтобы решить его, нужно понять как мне корректно поставить и использовать pytest.

## Как управлять зависимостями?
Можно использовать только [virtualenv](https://virtualenv.pypa.io/en/latest/) и requirements.txt. Можно быть прогрессивным и использовать [poetry](https://poetry.eustace.io/). Я же, пожалуй, воспользуюсь [tox](https://tox.readthedocs.io/en/latest/) - средство для упрощения автоматизации и тестирования, который также позволит мне управлять завимостями.

Создаю простой конфиг tox.ini и установлю pytest:
```
[tox]
envlist = py37  ; запускать на одной предопределенной среде

[testenv]  ; секция описания тестового окружения
deps = секция `deps` описываются зависимости, которые требуется доставить.
    -r requirements.txt ; доставить зависимости самого пакета
    -r requirements_test.txt ;
commands = pytest  ; запускаем тесты
```
Изначально я явно указывал зависимости, но практика интеграции со сторонними сервисами показали, что лучшим способом будет все-таки хранение зависимостей в `requirements.txt` файле.

Возникает очень тонкий момент. Фиксировать актуальную на момент разработки версию или всегда ставить последнюю?

Если фиксировать, то при установке могут возникнуть конфликты между пакетами из-за различных используемых версий завимосимостей. Если же не фиксировать, то пакет может неожиданно перестать работа. Последняя ситуация очень неприятная для конечных продуктов, когда в одну ночь все билды могут "покраснеть" из-за минорного обновления неявной зависимости. И по [закону Мерфи](https://en.wikipedia.org/wiki/Murphy%27s_law) это произойдет в день релиза.

Поэтому для себя выработал правило:
1. Всегда фиксировать версию для конечных продуктов, так как какие версии использовать - это их ответственность.
2. Не фиксировать используемую версию для устанавливаемых пакетов. Или ограничивать диапазоном, если того требует функционал пакета.

## Что дальше?
Пишем тесты! 

Заполняю тело функций и заставляю тесты проходить.
На этом моменте обычно большинство разработчиков останавливается (я все-таки верю, что большинство пишет тесты =), публикуют пакет и отгребают баги. Но мы не такие, мы идем дальше.

## Как работать с различными версиями python?
В конфигурации tox указываю запуск тестов на всех интересующих версиях python:
```
[tox]
envlist = py{27,35,36,37,38,py}
```
С помощью [pyenv](https://khashtamov.com/ru/pyenv-python/) доставляю нужные версии к себе локально, чтобы `tox` мог их найти и создать тестовые среды.

## Где заветные 100%?
Добавлю замер покрытия кода - для этого есть отличный пакет [coverage](https://coverage.readthedocs.io/en/v4.5.x/) и не менее прекрасная интеграция с pytest - [pytest-cov](https://github.com/pytest-dev/pytest-cov).
Меняю команду запуска теста:
```
deps =
    -r requirements.txt
    -r requirements_test.txt
commands = pytest \           
    --cov=src/ \                     
    --cov-config "{toxinidir}/tox.ini" \           
    --cov-append
```
`requirements_test.txt` выглядит теперь так:
```
six
pytest
pytest-cov
parameterized
```
Я сознательно не фиксирую версию, хотя это стоит сделать, так как эти зависимости "внутренние", только для тестов пакета.

Делаю сбор статистики покрытия для всего кода - самого пакета (*numeral-system/*) и обязательно для кода тестов (*tests/*) - я же не хочу, чтобы сами тесты содержали неисполняющиеся части?
Командой `--cov-append` всю собранную статистику для каждого вызова под различной версией python суммирую в одну, потому что покрытие для второго и третьего питона может быть различным (привет зависимый от версии код и модуль [six](https://pypi.org/project/six/)!), но по итогу в сумме давать 100% покрытие. Простой пример:
```
if sys.version_info > (3, 0):
    # Python 3 code in this block
else:
    # Python 2 code in this block
```

Добавляю новую среду для создания coverage отчета.
```
[testenv:coverage_report]
deps = coverage
commands =
    coverage html  ; данные уже есть, посторим отчет
    coverage report --include="numeral-system/*,tests/*" --fail-under=100 -m
```
И добавляю в список сред после выполнения тестов на всех версиях питона.

```
[tox]
envlist =
    py{27,35,36,37,38,py}
    coverage_report
```
После выполнения в корне проект должна появится папка `htmlconv` и файлом `index.html` в ней с красивым отчетом.

Для заветного бейджа в 100% интегрирую с сервисом [codecov](https://codecov.io/), который сам уже сделает интеграцию с github и позволит просмотреть историю измения покрытия кода. Для этого, конечно же, придется завести там аккаунт.
Итоговая среда запуска выглядит следующим образом:
```
[testenv:coverage_report]
passenv = TOXENV CI TRAVIS TRAVIS_* CODECOV_* APPVEYOR APPVEYOR_*
deps =
    coverage  ; ставим последний пакет итеграции с coverage
    codecov  ; ставим последний пакет итеграции с codecov
commands =
  coverage report --include="numeral_system/*,tests/*" --fail-under=100 -m
  coverage html
  coverage xml
  codecov -f coverage.xml --token=2455dcfa-f9fc-4b3a-b94d-9765afe87f0f  ; Токен моего проекта в codecov, смотреть в аккаунте
```
TODO Поменять бейдж на rst
Осталось теперь только добавить ссылку на бейдж в свое README.md
```
[![Code Coverage](https://codecov.io/gh/zifter/numeral-system-py/branch/master/graph/badge.svg)][codecov-url]
```

## Как анализировать код?
Интегрирую со статическими анализаторами кода [pylint](https://www.pylint.org/) и [flake8](http://flake8.pycqa.org/en/latest/) - они не только ищут проблемы в коде, но проверяют на соответствие [PEP8](https://www.python.org/dev/peps/pep-0008/).
Много анализаторов не бывает, потому что они, по большей части, дополняют друг другу.

Интеграция элементарная - добавляю новые тестовые среды:
```
[tox]
envlist =
    flake8
    pylint
    py{27,34,35,36,37,py}
    coverage_report

[testenv:flake8]
deps = flake8
commands = flake8

[testenv:pylint]
deps = pylint
commands = pylint --rcfile=tox.ini numeral_system/ tests/
```

Сразу же напарываюсь на странные ограничения - 100 символов в строке, имена функций в 30 символов (да, я пишу очень длинные имена тестовых методов) и предупреждения на наличие TODO в коде. Приходится добавить пару исключений:
```
[MESSAGES CONTROL]
disable=fixme,invalid-name

[flake8]
max-line-length = 120
```
А куда писать эти параметры для тонкой настройки? Для этого можно использовать `tox.ini` файл, `setup.cfg` или любой кастомный на ваш вкус. Я решил воспользоваться непосредственно `tox.ini`, так как можно будет просто копировать только `tox.ini` для будующих проектов.

Так же неприятный момент в том, что разработчики pylint уже похранили python2.7 и не развивают большего пакет для него. Поэтому проверки стоит запускать на актуальном пакете для python3.7.
Добавляю соответствующую строчку в конфигурацию.
```
[tox]
envlist =
    flake8
    pylint
    py{27,34,35,36,37,py}
    coverage_report
basepython = python3.7
```
Кстати, это так же важно для запуска тестов на различных платформах, так как дефолтная версия питона в системах различная.

## Что там с CI?
### Appveyor
Интегрирую с [appveyor](https://www.appveyor.com/) - CI под виндой. Первичная настройка простая - все можно сделать в интерфейсе, затем скачать yaml файл и закоммитеть его в репозиторий.
```
version: 0.0.{build}
init:
- cmd: choco install python.pypy
install:
- cmd: >-
    C:\\Python37\\python -m pip install --upgrade pip
    C:\\Python37\\pip install tox
build: off
test_script:
- cmd: C:\\Python37\\tox
```
Здесь я явно указываю версию `python3.7`, так как по умолчанию будет использован `python2.7` (и `tox` так же будет использовать эту версию, хоть я явно и указал `python3.7`).
Ссылка на бейдж, как обычно, добавляется в README.rst
TODO Поменять бейдж на rst
```
[![Build status Appveyor](https://ci.appveyor.com/api/projects/status/github/zifter/numeral-system-py?branch=master&svg=true)][appveyor-url]
```

### Travis CI
После, интегрирую с [Travis CI](https://travis-ci.org/) - CI под Linux (и под MacOS c Windows, но [`Python builds are not available on the macOS and Windows environments`](https://docs.travis-ci.com/user/languages/python/#what-this-guide-covers). Настройка чуть сложнее, так как конфигурационный файл будет использоваться непосредственно из репозитория. Пару итераций проб и ошибок - конфигурация готова. Сквошу в один красивый коммит и merge request готов.
```
language: python
python: 3.8  # 

dist: xenial    # required for Python 3.7 (travis-ci/travis-ci#9069)
sudo: required  # required for Python 3.7 (travis-ci/travis-ci#9069)

addons:
  apt:
    sources:
      - deadsnakes
    packages:
      - python3.5
      - python3.6
      - python3.7
      - pypy

install:
  - pip install tox

script:
  - tox
```
(*Риторический вопрос: И почему CI проектам так нравится yaml формат?*)

Указываем версию `python3.8`, так как установить ее через `addon` корректно не получилось, а `Travis CI` создает `virtualenv` указанной версии автоматом.
Люди, знакомые с Travis CI, могут вопросить, почему таким образом явно не указать версии python? Ведь `Travis CI` создает автоматически `virtualenv` и выполнит нужные команды в нем.

Причина в том, что нам нужно собрать данные по покрытию кода со всех версий. Но тесты будут запущены в разных джобах паралельно, из-за чего собрать общий отчет по покрытию не получится.
Конечно же, я уверен, что чуть больше разобравшись и это будет исправлено.

Ах да, самое важное, ссылка на бейдж так же добавляется в README.rst
TODO Поменять бейдж на rst
```
[![Build Status Travis CI](https://travis-ci.org/zifter/numeral-system-py.svg?branch=master)][travis-url]
```

## Документация
Думаю, каждый python разработчик хоть раз пользовался сервисом - [readthedocs.org](https://readthedocs.org/), мне кажется это лучший сервис для хостига своей документации.
Воспользуюсь стандартным средством для генерации документации [Sphinx](http://www.sphinx-doc.org/en/master/).
Выполняю шаги из (стартового мануала](https://docs.readthedocs.io/en/stable/intro/getting-started-with-sphinx.html] и получаю следующую структуру:
```
src/  
docs/ 
    build/  # здесь будут располагатся документация в html формате
    source/  # исходники для генерации документации
        _static/  # сюда положим статику, например, картинки
        _templates/  # шаблоны для генерации документации
        conf.py  # настройка генерации документов
        index.rst  # описание стартовой страницы
    make.bat  
    Makefile  # make для сборки с помощью make
```
Далее нужно проделать минимальные шаги для настройки:
1. `github.com` по умолчанию предлагает создать README.md файл в формате [Markdown](https://en.wikipedia.org/wiki/Markdown), когда как sphinx по умолчанию предлагает использовать [ReStructuredText](https://en.wikipedia.org/wiki/ReStructuredText).
Поэтому пришлось переписать его в формате .rst ~или хоть раз дочитать до конца стартовый мануал и понять что sphinx умеет и в Markdown~.
Добавляю include на README.rst в index.rst
```
.. include:: ../../README.rst
```

1. Для автогенерации документации из комментариев в исходниках добавляю расширение [sphinx.ext.autodoc](http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html). 

1. Добавляю папку с пакетом в `conf.py`. Это позволит sphinx делать импорты нашего кода для анализа.
```
import os
import sys
sys.path.insert(0, os.path.abspath('./../../src'))

import numeral_system
```

1. Добавляю папку `docs/source/api-docs` и закидываю туда файл описания каждого модуля. Описание должно магически сгенерироваться из комментариев.
```
Roman numeral system
=========================

.. automodule:: numeral_system.roman
   :members:
```

После этих минимальных действий проект готов явить миру свое описание. Нужно создать аккаунт (через аккаунт на `github`) и импортировать свой проект, подробные шаги описаны в [инструкции](https://github.com/readthedocs/readthedocs.org/blob/master/README.rst).
По традиции создаю среду в tox:
```
[testenv:gen_docs]
deps = -r docs/requirements.txt
commands =
    sphinx-build -b html docs/source/ docs/build/
```
Использую команду `sphinx-build` явно, вместо `make`, так как ее под windows нет. А я не хочу нарушать принцип о кроссплатформенной разработке.

Как только сделанные изменения замержились, `readthedocs.org` автоматически соберет документацию и опубликует.
Но... [`Build failed`](https://github.com/readthedocs/readthedocs.org/issues/2569).

Я не зафиксировал версии `sphinx` и `sphinx_rtd_theme`, и ожидал что `readthedocs.org` возьмет актуальные версии. Но это не так.
Фиксирую:
```
sphinx==2.3.1
sphinx_rtd_theme==0.4.3
```
И создаю специальный конфиг файл `.readthedocs.yml` для `readthedocs.org`, в котором описываю среду для запуска билда:
```
python:
   version: 3.7
   install:
      - requirements: docs/requirements.txt
      - requirements: requirements.txt
```
Вот здесь как раз и помог тот факт, что зависимости лежат в `requirements.txt` файлах.

Дожидаюсь билда и [документация становиться доступной](https://numeral-system-py.readthedocs.io/en/latest/).

## Лицензирование
Стоит подумать о выборе лицензии для пакета. 
Это очень обширная тема, поэтому ознакомился c [этой статьей](https://habr.com/ru/post/243091/). 
В принципе, выбор стоит между [MIT](http://directory.fsf.org/wiki/License:Expat) и [Apache 2.0](http://directory.fsf.org/wiki/License:Apache2.0). Мне понравилась удачно вырванная из контекста фраза:
```
MIT предлагают использовать лишь для небольших проектов
```
Согласен полностью, так и поступлю. 
Если планы поменяются, можно без проблем сменить лицензию (правда, предыдущие версии будут под старой).
TODO Добавить бейдж

## Как залить на pypi?
Для начала нужно завести аккаунт на [pypi.org](https://pypi.org). Затем приступить к подготовке пакета.

### Пишем setup.cfg
Нужно корректно описать конфигурацию для установки\сборки пакета. Я следовал [инструкции](https://docs.python.org/3/distutils/introduction.html). Есть возможность задать данные через `setup.py`, но некоторые парметры задать возможности нет. Поэтому воспользоваться `setup.cfg` файлом, в котором можно указать все ньюансы. Нашел [небольшой шаблон](https://gist.github.com/althonos/6914b896789d3f2078d1e6237642c35c) того, как заполнять этот файл. По итогу использую и тот и тот файл, так как так удобнее.
Этот файл также можно использовать для конфигурации `pylint`, `flake8` и прочих настроек (но я так не сделал).

### Как собрать пакет?
Снова пишу среду, которая поможет мне собрать необходимый пакет:
```
[testenv:build_wheel]
skip_install = True
deps = ; зависимости для сборки проекта
    wheel  
    docutils
commands =    
    python -c 'import shutil; (shutil.rmtree(p, ignore_errors=True) for p in ["build", "dist"]);' 
    python setup.py sdist bdist_wheel
```
Зачем я удаляю папки с помощью python? Xочу соблюсти требование о кроссплатформенности разработки, удобного пути сделать это под Windows и Linux нет.

Запускаю тестовую среду:
```
tox -e build_wheel
```
В результате в папке `dist` получаю:
```
dist/
    numeral-system-0.2.0.tar.gz
    numeral_system-0.2.0-py2.py3-none-any.whl
```

### Заливаем!
Не совсем. 

Для начала стоит проверить, что пакет работает корректным образом. Сначала залью в тестовый репозиторий пакетов.
Поэтому нужно завести еще один аккаунт, но уже на [test.pypi.org](https://test.pypi.org/).

Использую для этого пакет [twine](https://pypi.org/project/twine/) - инструмент для заливки артефактов в PyPi.
```
[testenv:test_upload]
skip_install = True
deps = twine ; ставлю последнюю версию
commands =    
     python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*
```
Изначально проект назывался `numsys`, но при попытке заливки сталкнулся с тем, что пакет с таким именем уже есть! И что самое обидное - он тоже умеет конвертировать в римские цифры :)
Сильно не расстроился и переименовал в numeral-system-py.

Теперь нужно установить пакет из тестового окружения. Проверку так же стоит автоматизировать:
```
[testenv:test_venv]
skip_install = True  ; не следует ставить текущий пакет в эту среду 
deps = ; пустые зависимости
commands =
    pip install -i https://test.pypi.org/simple/ numeral-system
```

Теперь нужно только запустить:
```
tox -e test_venv
...
test_venv: commands_succeeded
congratulations :)
```
Вроде работает :)

### Вот теперь точно заливаем!
Да.

Создаю среду для заливки в production репозиторий.
```
[testenv:pypi_upload]
skip_install = True
deps =
    twine
commands =
    python -m twine upload dist/*
```

И среду для production проверки.
```
[testenv:pypi_venv]
skip_install = True
deps = ; не ставим зависимости
commands =
    pip install numeral-system
```

### А вcе точно работает?
Проверяю простыми командами:
```
> virtualenv venv
> source venv/bin/activate
(venv) > pip install numeral-system
(venv) > python
>>> import numeral_system
>>> numeral_system.roman.encode(7)
'VII'
```
Все отлично!

[Срезаю релиз на github](https://help.github.com/en/articles/creating-releases), собираю пакет и заливаю в продовский pypi.

## Пару замечаний
### Обновления зависимостей
За время подготовки этой статьи была выпущена новыя версия pytest, в которой, по факту, дропнули поддержку python 3.4 ([на самом деле](https://github.com/tox-dev/tox/issues/1483) в пакете [colorama](https://github.com/tartley/colorama)). Вариантов было два:
1. зафиксировать версию colorama, совместимую с 3.4;
1. дропнуть поддержку 3.4 :)
В пользу второго варианта последним аргументом стало то, что и pip дропнул поддержку 3.4 в версии 19.1.

### TravisCI
Не поддерживает python для MacOS и Windows. 
Есть сложности с запуском `tox` под все версии питона в рамках одной джобы.

### Версия пакета
Нужно придерживаться [семантического версионирования](https://semver.org/), а именно формата 
```
MAJOR.MINOR.PATCH
```

### Дублирования мета информации
Версию пакета и некоторые другие параметры требуется указывать для установки пакета (в `setup.cfg` или `setup.py`) и в документации. Чтобы избежать дублирования сделал указание только в пакете `numeral_system/__init__.py`:
```
__version__ = '0.2.0'
```
А затем в setup.py явно использую эту переменную
```
setup(
    version=numeral_system.__version__,
)
```
Тоже верно и для в `docs/source/conf.py`
```
release = numeral_system.__version__
```
Вышеописанное справедливо для любой мета информации - REAMDE.rst, описания проекта, лицензии, имена автора и прочего.
Есть возможность указать этот аттрибут и в setup.cfg через префикс `attr:`, но это работает только для версии, что не удобно.
Но это приводит к тому, что происходит импорт пакета в момент сборки, что может быть не желательным.

### Дублирование зависимостей
Вначале работы меня смущал тот факт, что мне нужно указывать зависимости для пакета в requirements.txt и setup.cfg.
Затем почитал [отличную статью](https://caremad.io/posts/2013/07/setup-vs-requirement/), которая разъяснила - указывать нужно только в `setup.cfg`.

## Заключение или можно ли сделать лучше?
На этом останавливаться все равно не стоит, можно сделать еще улучшения:
* Тестирования на python x64 и x86;
* Добавить перфоманс регрессию;
* Добавить поддержку MacOS;
* 100% покрытие кода далеко не показатель качества, тесты должны покрывать все ветки исполнения. Как [это](https://en.wikipedia.org/wiki/Cyclomatic_complexity) мерить?
* Зависимости обновляются и это следует отслеживать через [PyUp]](https://PyUp.io) или [requires.io](https://requires.io/). Как лучше?;
* Нужно больше статик анализаторов. Что есть еще?
* Стоит ли использовать [black](https://black.readthedocs.io/en/stable/) вместо flake8?

Определенно, можно сделать гораздно лучше. 
Придется написать не одну библиотеку и поконтрибьютить не в один open-source проект, чтобы разобраться со всеми тонкостями.
Во время подготовки к статье я прочитал не один десяток мануалов, посмотрел еще больше python проектов на `github`, протестировал разные сервисы и их варианты конфигурации.
Но больше всего времени я провел на stackoverflow и issues конкретных проектов на `github`, так все эти сервисы так и наровят упасть с очередной непонятной ошибкой. Когда следует остановится с интеграциями?..

Тем, кто заинтересовался, советую так же прочитать [статью с похожей тематикой](https://habr.com/ru/company/ruvds/blog/444344/).
[Проект можно потрогать на github](https://github.com/zifter/numeral-system-py)
